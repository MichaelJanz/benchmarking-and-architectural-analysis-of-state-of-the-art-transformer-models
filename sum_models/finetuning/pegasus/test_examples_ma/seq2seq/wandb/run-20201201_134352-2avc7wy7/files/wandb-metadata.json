{
    "os": "Linux-5.4.0-53-generic-x86_64-with-debian-bullseye-sid",
    "python": "3.7.9",
    "heartbeatAt": "2020-12-01T12:43:53.439355",
    "startedAt": "2020-12-01T12:43:52.522722",
    "docker": null,
    "gpu": "GeForce RTX 2070",
    "gpu_count": 1,
    "cpu_count": 12,
    "cuda": "11.0.207",
    "args": [
        "--data_dir=./finetune_ds_overlap/",
        "--model_name_or_path=facebook/bart-large-cnn",
        "--learning_rate=3e-5",
        "--train_batch_size=1",
        "--eval_batch_size=1",
        "--output_dir=/mnt/01D64EB52A75D220/Users/Science/Documents/Projekte/MA/sum_models/pegasus/pegasus/transformers/test_examples_ma/seq2seq/bart_utest_output",
        "--num_train_epochs=10",
        "--gpus=1",
        "--freeze_encoder",
        "--freeze_embeds",
        "--max_target_length=500",
        "--val_max_target_length=500",
        "--test_max_target_length=500",
        "--encoder_layerdrop",
        "0.2",
        "--early_stopping_patience",
        "3",
        "--do_train",
        "--logger_name",
        "wandb",
        "--val_metric=rouge2"
    ],
    "state": "running",
    "codePath": "test_examples_ma/seq2seq/finetune.py",
    "program": "finetune.py",
    "git": {
        "remote": "git@github.com:MichaelJanz/ma.git",
        "commit": "b0cbcdb05b39e6c81db049d2b4d7dfc5d823210d"
    },
    "email": "kontakt@michaeljanz-data.science",
    "root": "/mnt/01D64EB52A75D220/Users/Science/Documents/Projekte/MA/sum_models/pegasus/pegasus/transformers",
    "host": "science-B450-AORUS-PRO",
    "username": "science",
    "executable": "/home/science/anaconda3/envs/tr_pegasus_env/bin/python"
}
